{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> TPX - MATERIA XX - MIA </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">üìù <em><small><font color='Gray'>Nota:</font></small></em></div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> La funcionalidad de visualizaci√≥n de jupyter notebooks en <a href=\"https://github.com/\" target=\"_blank\">github</a> es solamente un preview.</font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Para mejor visualizaci√≥n se sugiere utilizar el visualizador recomendado por la comunidad: <a href=\"https://nbviewer.org/\" target=\"_blank\">nbviewer</a></font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Puedes a acceder al siguiente enlace para ver este notebook en dicha p√°gina: <a href=\"https://nbviewer.org/ruta/de/archivo.ipynb\">Ruta archivo</a></font></small></em> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõª <em><font color='MediumSeaGreen'>  Instalaciones: </font></em> üõª\n",
    "\n",
    "Este notebook utiliza [Poetry](https://python-poetry.org/) para la gesti√≥n de dependencias.\n",
    "Primero instala Poetry siguiendo las instrucciones de su [documentaci√≥n oficial](https://python-poetry.org/docs/#installation).\n",
    "Luego ejecuta el siguiente comando para instalar las dependencias necesarias y activar el entorno virtual:\n",
    "\n",
    "- Bash:\n",
    "```bash\n",
    "poetry install\n",
    "eval $(poetry env activate)\n",
    "```\n",
    "\n",
    "- PowerShell:\n",
    "```powershell\n",
    "poetry install\n",
    "Invoke-Expression (poetry env activate)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Descargar archivos adicionales:\n",
    "!gdown https://drive.google.com/drive/folders/1UBZ8PEbtmiWMGkULu7GAt3VhUpeTy9l7?usp=sharing --folder -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "\n",
    "# 20newsgroups por ser un dataset cl√°sico de NLP ya viene incluido y formateado\n",
    "# en sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "# System information\n",
    "import platform, psutil, GPUtil, gc\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "\n",
    "# Limpiar GPU\n",
    "def clean_gpu_usage() -> None:\n",
    "    \"\"\"Permite mostrar el uso y limpiar el chache de la GPU\"\"\"\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "# Mostrar informaci√≥n total del sistema.\n",
    "def show_system_info():\n",
    "    \"\"\"Funci√≥n que permite visualizar las especificaciones del sistema\"\"\"\n",
    "    system_info = platform.uname()\n",
    "\n",
    "    print(\"System Information:\")\n",
    "    print(f\"System: {system_info.system}\")\n",
    "    print(f\"Node Name: {system_info.node}\")\n",
    "    print(f\"Release: {system_info.release}\")\n",
    "    print(f\"Version: {system_info.version}\")\n",
    "    print(f\"Machine: {system_info.machine}\")\n",
    "    print(f\"Processor: {system_info.processor}\")\n",
    "\n",
    "    cpu_info = platform.processor()\n",
    "    cpu_count = psutil.cpu_count(logical=False)\n",
    "    logical_cpu_count = psutil.cpu_count(logical=True)\n",
    "\n",
    "    print(\"\\nCPU Information:\")\n",
    "    print(f\"Processor: {cpu_info}\")\n",
    "    print(f\"Physical Cores: {cpu_count}\")\n",
    "    print(f\"Logical Cores: {logical_cpu_count}\")\n",
    "\n",
    "    memory_info = psutil.virtual_memory()\n",
    "\n",
    "    print(\"\\nMemory Information:\")\n",
    "    print(f\"Total Memory: {memory_info.total} bytes\")\n",
    "    print(f\"Available Memory: {memory_info.available} bytes\")\n",
    "    print(f\"Used Memory: {memory_info.used} bytes\")\n",
    "    print(f\"Memory Utilization: {memory_info.percent}%\")\n",
    "\n",
    "    disk_info = psutil.disk_usage('/')\n",
    "\n",
    "    print(\"\\nDisk Information:\")\n",
    "    print(f\"Total Disk Space: {disk_info.total} bytes\")\n",
    "    print(f\"Used Disk Space: {disk_info.used} bytes\")\n",
    "    print(f\"Free Disk Space: {disk_info.free} bytes\")\n",
    "    print(f\"Disk Space Utilization: {disk_info.percent}%\")\n",
    "\n",
    "    gpus = GPUtil.getGPUs()\n",
    "\n",
    "    if not gpus:\n",
    "        print(\"No GPU detected.\")\n",
    "    else:\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"\\nGPU {i + 1} Information:\")\n",
    "            print(f\"ID: {gpu.id}\")\n",
    "            print(f\"Name: {gpu.name}\")\n",
    "            print(f\"Driver: {gpu.driver}\")\n",
    "            print(f\"GPU Memory Total: {gpu.memoryTotal} MB\")\n",
    "            print(f\"GPU Memory Free: {gpu.memoryFree} MB\")\n",
    "            print(f\"GPU Memory Used: {gpu.memoryUsed} MB\")\n",
    "            print(f\"GPU Load: {gpu.load * 100}%\")\n",
    "            print(f\"GPU Temperature: {gpu.temperature}¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 22 21:44:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8             11W /  320W |    1314MiB /  16376MiB |     36%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1796    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe      N/A      |\n",
      "|    0   N/A  N/A      9420    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A      9820    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10396    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A     11148    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11420    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11444    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12776    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A     15280    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     15696    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     15808    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16040      C   ...iles\\obs-studio\\bin\\64bit\\obs64.exe      N/A      |\n",
      "|    0   N/A  N/A     17672    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23704    C+G   ... Software\\IntelGraphicsSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A     27440    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     29596    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo actual: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # Establece el dispositivo.\n",
    "\n",
    "# Par√°metros\n",
    "BATCH_SIZE = 10 # Tama√±o del batch\n",
    "N_EPOCHS = 10 # N√∫mero de √©pocas\n",
    "VERBOSE = True # Muestra √©poca a √©poca la evoluci√≥n\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'Dispositivo actual: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Colab -->\n",
    "<!-- <div align=\"center\"><img src=\"https://drive.google.com/uc?export=view&id=1QSNrTsz1hQbmZwpgwx0qpfpNtLW19Orm\" width=\"600\" alt=\"Figura 1: A data scientist is working on word generation using the Lord of the Rings lore. The image is dark and moody, with a focus on the scientist's computer screen. The screen displays a visualization the one ring, with a map of Middle Earth in the background. - Generada con DALL-E3\"></div> -->\n",
    "\n",
    "<div align=\"center\"><img src=\"./ceia-materia/resources/portada.jpeg\" width=\"600\" alt=\"Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator\"></div>\n",
    "\n",
    "<div align=\"center\"><small><em>Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator</em></small></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | Desaf√≠o 1 - NLP - FIUBA                                                                                                                |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | Word vectorizer + Naive bayes                                                                                                          |\n",
    "| **Integrantes** | Bruno Masoller (brunomaso1@gmail.com)                                                                                                  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consinga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resoluci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()\n",
    "# Fieteamos y transformamos el conjunto X_train\n",
    "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
    "# Obtenemos el conjunto y_train\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "# Obtenemos tambi√©n el diccionario inverso\n",
    "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}\n",
    "tfidfvect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alerts examples:\n",
    "https://github.com/orgs/community/discussions/16925\n",
    "\n",
    "Funciona solamente en markdown el preview de github, no en nbviewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]  \n",
    "> Highlights information that users should take into account, even when skimming.\n",
    "\n",
    "> [!TIP]\n",
    "> Optional information to help a user be more successful.\n",
    "\n",
    "> [!IMPORTANT]  \n",
    "> Crucial information necessary for users to succeed.\n",
    "\n",
    "> [!WARNING]  \n",
    "> Critical content demanding immediate user attention due to potential risks.\n",
    "\n",
    "> [!CAUTION]\n",
    "> Negative potential consequences of an action.\n",
    "\n",
    "> [!CAUTION] CUSTOM NAME\n",
    "> TEST TEST TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Detalles</summary>\n",
    "  <ul>\n",
    "    <li>\n",
    "      <em>Generaci√≥n de claves SSH:</em> Para la generaci√≥n de claves SSH, primeramente hay que generar un par de claves (privada y\n",
    "      p√∫blica) en la m√°quina actual. Esto se puede hacer con <code>ssh-keygen</code> o, en su defecto, con PuTTYgen\n",
    "      tambi√©n. Esto \n",
    "      Ejemplo: <code>ssh-keygen -t ed25519 -C \"login\" -Z aes256-gcm@openssh.com</code>. Luego, hay que subir estas\n",
    "      claves a la \"Organizaci√≥n\" en <samp>Organization -> SSH Keys -> Add SSH key</samp>.\n",
    "      Es de destacar, que esta clave se copia a la instancia una vez se crea la misma autom√°ticamente.      \n",
    "    </li>\n",
    "    <li>\n",
    "      <em>Generaci√≥n de clave API Key:</em> Para crear una API Key es simplemente ir a <samp>Organization -> API Keys -> Generate AP√è Key</samp>. Hay que poner que se utilizar√° para acceder al bucket tambi√©n.\n",
    "    </li>\n",
    "  </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom alerts examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõª <em><font color='MediumSeaGreen'>  Instalaciones: </font></em> üõª\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üîÆ <em><font color='violet'>Funci√≥n auxiliar:</font></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚≠ê <em><strong>Conclusi√≥n:</strong></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è <em><font color='gold'>PROBLEMAS DETECTADOS:</font></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù <em><font color='Gray'>Nota:</font></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí´ <em><font color='MediumPurple'> Mejoras posibles: </font></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° <em><font color='IndianRed'>Hip√≥tesis:</font></em> [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in felis ut est molestie eleifend. Aliquam luctus lacinia diam vel cursus. Fusce ipsum mauris, dictum at dignissim eu, tristique in magna. Maecenas iaculis nisi elit, id molestie nibh egestas quis. Nulla tempus rutrum ipsum, at iaculis mauris efficitur sit amet. Etiam ut tincidunt magna.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los requrimientos para reproducci√≥n local\n",
    "%pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
