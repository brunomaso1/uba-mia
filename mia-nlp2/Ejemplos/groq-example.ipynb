{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4843ec",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> GROQ EXAMPLE </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd82c9",
   "metadata": {},
   "source": [
    "<div align=\"right\">üìù <em><small><font color='Gray'>Nota:</font></small></em></div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> La funcionalidad de visualizaci√≥n de jupyter notebooks en <a href=\"https://github.com/\" target=\"_blank\">github</a> es solamente un preview.</font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Para mejor visualizaci√≥n se sugiere utilizar el visualizador recomendado por la comunidad: <a href=\"https://nbviewer.org/\" target=\"_blank\">nbviewer</a></font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Puedes a acceder al siguiente enlace para ver este notebook en dicha p√°gina: <a href=\"https://nbviewer.org/github/brunomaso1/uba-mia/blob/mia-nlp2/mia-nlp2/Ejemplos/groq-example.ipynb\">Groq example</a></font></small></em> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9838a",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38903ad6",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4f11b",
   "metadata": {},
   "source": [
    "<!-- Colab -->\n",
    "<!-- <div align=\"center\"><img src=\"https://drive.google.com/uc?export=view&id=1QSNrTsz1hQbmZwpgwx0qpfpNtLW19Orm\" width=\"600\" alt=\"Figura 1: A data scientist is working on word generation using the Lord of the Rings lore. The image is dark and moody, with a focus on the scientist's computer screen. The screen displays a visualization the one ring, with a map of Middle Earth in the background. - Generada con DALL-E3\"></div> -->\n",
    "\n",
    "<div align=\"center\"><img src=\"../resources/img1.jpeg\" width=\"600\" alt=\"Figura 1: A data scientist is sitting in front of a computer screen, intently focused on the task at hand. The room is dimly lit, with the only light coming from the computer screen. The neural network is displayed on the screen, with the data scientist working to. The nerual network is deepseek R1. - Generada con Microsoft Image Creator\"></div>\n",
    "\n",
    "<div align=\"center\"><small><em>Figura 1: A data scientist is sitting in front of a computer screen, intently focused on the task at hand. The room is dimly lit, with the only light coming from the computer screen. The neural network is displayed on the screen, with the data scientist working to. The nerual network is deepseek R1. - Generada con Microsoft Image Creator</em></small></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c31878",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | Ejemplo de prueba de Groq                                                                                                              |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | Ejemplo de prueba de funcionamiento de la api de Groq                                                                                  |\n",
    "| **Integrantes** | Bruno Masoller (brunomaso1@gmail.com)                                                                                                  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1183df5",
   "metadata": {},
   "source": [
    "üõª <em><font color='MediumSeaGreen'>  Instalaciones: </font></em> üõª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc484b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: groq in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (2.11.2)\n",
      "Requirement already satisfied: sniffio in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq) (4.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-groq in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (2.11.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain-groq) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: sniffio in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.13.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\documentos\\git repositories\\uba-mia\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install groq\n",
    "%pip install langchain langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b333e8",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bcb271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56cb5f",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "LANGCHAIN_PROVIDER = \"groq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff65c6e",
   "metadata": {},
   "source": [
    "## Consinga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447fdbbb",
   "metadata": {},
   "source": [
    "Este notebook tiene como objetivo mostrar un ejemplo de prueba de funcionamiento de la API de Groq. Se utilizar√° el modelo de lenguaje Groq R1 para generar texto a partir de un prompt dado. El modelo se ejecutar√° en la plataforma Groq y se mostrar√° el resultado en la salida del notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548e223",
   "metadata": {},
   "source": [
    "## Resoluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843b19c",
   "metadata": {},
   "source": [
    "### API Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509edb",
   "metadata": {},
   "source": [
    "Los modelos que actualmente soporta Groq son: https://console.groq.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46024451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are a crucial component of natural language processing (NLP) and have numerous benefits in various applications. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Real-time Processing**: Fast language models enable real-time processing of text data, which is essential for applications like chatbots, virtual assistants, and sentiment analysis. They can quickly analyze and respond to user input, providing a seamless and interactive experience.\n",
      "2. **Improved User Experience**: Fast language models can significantly enhance user experience in applications like language translation, text summarization, and question answering. By providing rapid and accurate results, they help users to quickly understand and engage with content.\n",
      "3. **Scalability**: Fast language models can handle large volumes of text data and process it efficiently, making them ideal for large-scale applications like social media monitoring, customer service, and content analysis.\n",
      "4. **Resource Efficiency**: Fast language models require fewer computational resources and memory, making them more energy-efficient and cost-effective. This is particularly important for applications that need to process vast amounts of text data, such as web scraping and data mining.\n",
      "5. **Enhanced Accuracy**: Fast language models can be trained on larger datasets and can learn from more examples, which leads to improved accuracy and better language understanding. This, in turn, enables more effective applications like language translation, text classification, and named entity recognition.\n",
      "6. **Time-Critical Applications**: Fast language models are essential for time-critical applications like emergency response systems, where quick and accurate analysis of text data can be lifesaving.\n",
      "7. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by analyzing and responding to customer feedback, social media posts, and other text data in real-time, enabling them to make data-driven decisions and stay ahead of the competition.\n",
      "8. **Research and Development**: Fast language models accelerate research and development in NLP by enabling researchers to quickly experiment with different architectures, training methods, and applications, leading to new breakthroughs and innovations.\n",
      "\n",
      "Some of the key applications that benefit from fast language models include:\n",
      "\n",
      "* Virtual assistants (e.g., Siri, Alexa, Google Assistant)\n",
      "* Chatbots and customer service platforms\n",
      "* Language translation and localization\n",
      "* Sentiment analysis and opinion mining\n",
      "* Text summarization and content analysis\n",
      "* Question answering and knowledge retrieval\n",
      "* Social media monitoring and analytics\n",
      "* Emergency response systems and crisis management\n",
      "\n",
      "In summary, fast language models are vital for a wide range of applications, as they enable real-time processing, improve user experience, and provide a competitive advantage. Their importance will continue to grow as NLP becomes increasingly ubiquitous in various industries and aspects of life.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27068ed",
   "metadata": {},
   "source": [
    "### API Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c4c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa3331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1ddce",
   "metadata": {},
   "source": [
    "Invocaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd0890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je adore programmer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 55, 'total_tokens': 60, 'completion_time': 0.006666667, 'prompt_time': 0.002620288, 'queue_time': 0.211642856, 'total_time': 0.009286955}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a4265e44d5', 'finish_reason': 'stop', 'logprobs': None}, id='run-0afed031-902e-48a7-b718-e1389afb7374-0', usage_metadata={'input_tokens': 55, 'output_tokens': 5, 'total_tokens': 60})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59bf9ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je adore programmer.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb916f2",
   "metadata": {},
   "source": [
    "#### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e63559bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe Programmieren.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 50, 'total_tokens': 56, 'completion_time': 0.008, 'prompt_time': 0.005136357, 'queue_time': 0.212904009, 'total_time': 0.013136357}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_bc861211a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-e6460174-f964-4f35-9cca-01591bf56d2f-0', usage_metadata={'input_tokens': 50, 'output_tokens': 6, 'total_tokens': 56})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
